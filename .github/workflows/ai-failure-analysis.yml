name: AI-Powered Failure Analysis

on:
  workflow_run:
    workflows:
      - CI/CD
      - E2E Tests
      - Deploy to Render
      - Deploy to Vercel
    types:
      - completed

permissions:
  contents: read
  issues: write
  checks: read

jobs:
  analyze-failures:
    name: Analyze workflow failures with AI
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion == 'failure'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get workflow run details
        id: workflow
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          RUN_ID="${{ github.event.workflow_run.id }}"
          WORKFLOW_NAME="${{ github.event.workflow_run.name }}"
          
          # Get job details
          gh run view "$RUN_ID" --json jobs -q '.jobs[] | select(.conclusion=="failure") | .name' > /tmp/failed_jobs.txt
          
          # Get logs
          gh run view "$RUN_ID" --log > /tmp/workflow_logs.txt || true
          
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
          echo "workflow_name=$WORKFLOW_NAME" >> $GITHUB_OUTPUT

      - name: Analyze logs with AI (if OpenAI configured)
        id: ai_analysis
        if: env.OPENAI_API_KEY != ''
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          # Read workflow logs (truncated to first 2000 chars to save tokens)
          LOG_TEXT=$(head -c 2000 /tmp/workflow_logs.txt 2>/dev/null || echo "No logs available")
          
          # Create analysis prompt
          cat > /tmp/analysis_prompt.json <<EOF
          {
            "model": "gpt-3.5-turbo",
            "messages": [
              {
                "role": "system",
                "content": "You are a CI/CD expert. Analyze GitHub Actions workflow failures and provide concise root cause analysis and remediation steps. Be specific and actionable."
              },
              {
                "role": "user",
                "content": "Analyze this workflow failure and suggest fixes:\n\nWorkflow: ${{ steps.workflow.outputs.workflow_name }}\n\nLogs:\n$LOG_TEXT"
              }
            ],
            "max_tokens": 500,
            "temperature": 0.7
          }
          EOF
          
          # Call OpenAI API
          RESPONSE=$(curl -s -X POST https://api.openai.com/v1/chat/completions \
            -H "Authorization: Bearer $OPENAI_API_KEY" \
            -H "Content-Type: application/json" \
            -d @/tmp/analysis_prompt.json)
          
          # Extract analysis
          ANALYSIS=$(echo "$RESPONSE" | jq -r '.choices[0].message.content // "Unable to analyze failure"')
          echo "analysis<<EOF" >> $GITHUB_OUTPUT
          echo "$ANALYSIS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Prepare fallback analysis
        id: fallback_analysis
        if: failure() || steps.ai_analysis.outcome == 'skipped'
        run: |
          ANALYSIS="Failed to analyze with AI. Check logs:\n- Look for 'error', 'failed', 'timeout'\n- Review recent changes\n- Check environment variables\n- Verify service dependencies"
          echo "analysis<<EOF" >> $GITHUB_OUTPUT
          echo "$ANALYSIS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Create failure issue with analysis
        id: create_issue
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          ANALYSIS="${{ steps.ai_analysis.outputs.analysis || steps.fallback_analysis.outputs.analysis }}"
          
          ISSUE_BODY="## Workflow Failure Analysis

**Workflow:** ${{ steps.workflow.outputs.workflow_name }}
**Run ID:** ${{ steps.workflow.outputs.run_id }}
**Branch:** ${{ github.ref_name }}
**Commit:** ${{ github.sha }}

### ðŸ¤– AI Analysis

\`\`\`
$ANALYSIS
\`\`\`

### ðŸ“‹ Troubleshooting Steps

1. Review the [workflow logs](https://github.com/${{ github.repository }}/actions/runs/${{ steps.workflow.outputs.run_id }})
2. Check recent commits for breaking changes
3. Verify environment variables and secrets
4. Review service health status
5. Run workflow again to check for transient failures

### ðŸ”— Related Documentation

- [Workflow Guide](.github/WORKFLOW_GUIDE.md)
- [Troubleshooting](./SECURITY.md#troubleshooting)
- [Failure Runbook](./WORKFLOW_GUIDE.md#runbooks)

---

**Generated by AI Failure Analysis**"

          # Create issue
          gh issue create \
            --title "âš ï¸ Workflow Failure: ${{ steps.workflow.outputs.workflow_name }}" \
            --body "$ISSUE_BODY" \
            --label "ci-failure,ai-analysis" \
            --assignee "@me" \
            2>/dev/null || echo "Issue creation skipped (manual step may be needed)"

      - name: Generate optimization suggestions
        id: optimization
        if: env.OPENAI_API_KEY != ''
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          # Analyze workflow file for optimizations
          WORKFLOW_FILE=".github/workflows/${{ steps.workflow.outputs.workflow_name }}.yml"
          
          if [ -f "$WORKFLOW_FILE" ]; then
            CONTENT=$(head -c 1500 "$WORKFLOW_FILE")
            
            cat > /tmp/optimization_prompt.json <<EOF
            {
              "model": "gpt-3.5-turbo",
              "messages": [
                {
                  "role": "system",
                  "content": "You are a GitHub Actions expert. Suggest 3-5 specific optimizations to improve workflow performance and reliability."
                },
                {
                  "role": "user",
                  "content": "Suggest optimizations for this workflow:\n\n$CONTENT"
                }
              ],
              "max_tokens": 300,
              "temperature": 0.7
            }
            EOF
            
            RESPONSE=$(curl -s -X POST https://api.openai.com/v1/chat/completions \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -H "Content-Type: application/json" \
              -d @/tmp/optimization_prompt.json)
            
            SUGGESTIONS=$(echo "$RESPONSE" | jq -r '.choices[0].message.content // "No suggestions available"')
            echo "suggestions<<EOF" >> $GITHUB_OUTPUT
            echo "$SUGGESTIONS" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          fi

      - name: Log analysis summary
        run: |
          echo "## Failure Analysis Results"
          echo ""
          echo "**Workflow:** ${{ steps.workflow.outputs.workflow_name }}"
          echo "**Run ID:** ${{ steps.workflow.outputs.run_id }}"
          echo ""
          echo "### AI Analysis"
          echo "${{ steps.ai_analysis.outputs.analysis || steps.fallback_analysis.outputs.analysis }}"
          echo ""
          if [ -n "${{ steps.optimization.outputs.suggestions }}" ]; then
            echo "### Optimization Suggestions"
            echo "${{ steps.optimization.outputs.suggestions }}"
          fi

  detect-anomalies:
    name: Detect performance anomalies
    runs-on: ubuntu-latest
    if: success() && github.event.workflow_run.conclusion == 'success'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Fetch historical workflow data
        id: history
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Get last 10 successful runs
          gh run list \
            --workflow="${{ github.event.workflow_run.name }}.yml" \
            --json "databaseId,name,updatedAt,status" \
            --limit 10 > /tmp/runs.json || true

      - name: Analyze performance trends (if data available)
        if: env.OPENAI_API_KEY != '' && hashFiles('/tmp/runs.json') != ''
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          RUNS=$(cat /tmp/runs.json)
          
          cat > /tmp/anomaly_prompt.json <<EOF
          {
            "model": "gpt-3.5-turbo",
            "messages": [
              {
                "role": "system",
                "content": "Analyze workflow run history and identify performance anomalies or concerning trends. Be specific about which metrics changed."
              },
              {
                "role": "user",
                "content": "Analyze these workflow runs for anomalies:\n\n$RUNS"
              }
            ],
            "max_tokens": 400,
            "temperature": 0.7
          }
          EOF
          
          RESPONSE=$(curl -s -X POST https://api.openai.com/v1/chat/completions \
            -H "Authorization: Bearer $OPENAI_API_KEY" \
            -H "Content-Type: application/json" \
            -d @/tmp/anomaly_prompt.json)
          
          ANOMALIES=$(echo "$RESPONSE" | jq -r '.choices[0].message.content // "No anomalies detected"')
          echo "$ANOMALIES"

---

## Configuration

### Prerequisites
1. Set up OpenAI API key (optional, falls back to basic analysis)
   ```bash
   gh secret set OPENAI_API_KEY
   ```

2. Enable issue creation (workflow already has permissions)

### Features

âœ… **Automated Failure Analysis**
- AI-powered root cause identification
- Specific remediation suggestions
- Automatic issue creation

âœ… **Optimization Suggestions**
- Performance improvement recommendations
- Best practices identification
- Workflow-specific suggestions

âœ… **Anomaly Detection**
- Performance regression detection
- Trend analysis
- Historical comparison

### Cost Considerations

- Each analysis uses ~500 tokens (GPT-3.5)
- Typical cost: $0.001-0.005 per failure
- Consider adding cost controls in OpenAI account

### Fallback Behavior

If OpenAI API is unavailable:
- Basic failure analysis still runs
- Generic troubleshooting suggestions provided
- Issues still created with logs
- No token usage or costs

---

## Monitoring

**Issues Created:** Check GitHub Issues with label `ai-analysis`

**Status:** Review workflow runs in Actions tab

**Logs:** View full AI responses in workflow logs
