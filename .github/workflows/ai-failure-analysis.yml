name: AI-Powered Failure Analysis

on:
  workflow_run:
    workflows:
      - CI/CD
      - E2E Tests
      - Deploy to Render
      - Deploy to Vercel
    types:
      - completed

permissions:
  contents: read
  issues: write
  checks: read

jobs:
  analyze-failures:
    name: Analyze workflow failures with AI
    runs-on: ubuntu-latest
    if: |
      github.event.workflow_run.conclusion == 'failure' &&
      contains(fromJSON('["CI/CD Pipeline","E2E Tests","Deploy API (Render)","Deploy Web to Vercel"]'), github.event.workflow_run.name)
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get workflow run details
        id: workflow
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          RUN_ID="${{ github.event.workflow_run.id }}"
          WORKFLOW_NAME="${{ github.event.workflow_run.name }}"
          
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
          echo "workflow_name=$WORKFLOW_NAME" >> $GITHUB_OUTPUT
          
          # Get logs (may fail if not available, that's ok)
          gh run view "$RUN_ID" --log > /tmp/workflow_logs.txt 2>/dev/null || echo "Logs not available" > /tmp/workflow_logs.txt

      - name: Analyze logs with AI (if OpenAI configured)
        id: ai_analysis
        if: env.OPENAI_API_KEY != '' && env.OPENAI_API_KEY != 'null'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          # Read workflow logs (truncated to first 2000 chars to save tokens)
          LOG_TEXT=$(head -c 2000 /tmp/workflow_logs.txt 2>/dev/null || echo "No logs available")
          
          # Create analysis prompt
          cat > /tmp/analysis_prompt.json <<'EOF'
          {
            "model": "gpt-3.5-turbo",
            "messages": [
              {
                "role": "system",
                "content": "You are a CI/CD expert. Analyze GitHub Actions workflow failures and provide concise root cause analysis (max 3 sentences) and 2-3 specific remediation steps."
              },
              {
                "role": "user",
                "content": "Analyze this workflow failure and suggest fixes:\n\nWorkflow: ${{ steps.workflow.outputs.workflow_name }}\n\nLogs:\n$LOG_TEXT"
              }
            ],
            "max_tokens": 300,
            "temperature": 0.7
          }
          EOF
          
          # Call OpenAI API with timeout
          RESPONSE=$(timeout 10 curl -s -X POST https://api.openai.com/v1/chat/completions \
            -H "Authorization: Bearer $OPENAI_API_KEY" \
            -H "Content-Type: application/json" \
            -d @/tmp/analysis_prompt.json 2>/dev/null || echo '{"choices":[{"message":{"content":"API timeout"}}]}')
          
          # Extract analysis
          ANALYSIS=$(echo "$RESPONSE" | jq -r '.choices[0].message.content // "Unable to analyze failure"' 2>/dev/null || echo "AI analysis unavailable")
          echo "analysis<<EOF" >> $GITHUB_OUTPUT
          echo "$ANALYSIS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
        continue-on-error: false

      - name: Prepare fallback analysis
        id: fallback_analysis
        if: failure() || steps.ai_analysis.outcome == 'skipped'
        run: |
          ANALYSIS="Failed to analyze with AI. Check logs:\n- Look for 'error', 'failed', 'timeout'\n- Review recent changes\n- Check environment variables\n- Verify service dependencies"
          echo "analysis<<EOF" >> $GITHUB_OUTPUT
          echo "$ANALYSIS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Create failure issue with analysis
        id: create_issue
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          ANALYSIS="${{ steps.ai_analysis.outputs.analysis || steps.fallback_analysis.outputs.analysis }}"
          
          ISSUE_BODY="## Workflow Failure Analysis

**Workflow:** ${{ steps.workflow.outputs.workflow_name }}
**Run ID:** ${{ steps.workflow.outputs.run_id }}
**Branch:** ${{ github.ref_name }}
**Commit:** ${{ github.sha }}

### ðŸ¤– Analysis

\`\`\`
$ANALYSIS
\`\`\`

### ðŸ“‹ Next Steps

1. Review the [workflow logs](https://github.com/${{ github.repository }}/actions/runs/${{ steps.workflow.outputs.run_id }})
2. Check recent commits for changes
3. Verify environment and secrets
4. Run workflow again to confirm fix"
          
          # Create issue safely
          gh issue create \
            --title "âš ï¸ ${{ steps.workflow.outputs.workflow_name }} Failed" \
            --body "$ISSUE_BODY" \
            --label "ci-failure,ai-analysis" \
            2>/dev/null || echo "Issue creation skipped"
        continue-on-error: false

      - name: Generate optimization suggestions
        id: optimization
        if: env.OPENAI_API_KEY != '' && env.OPENAI_API_KEY != 'null'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          # Get workflow file name
          WORKFLOW_FILE_NAME=$(echo "${{ steps.workflow.outputs.workflow_name }}" | tr ' ' '-' | tr '[:upper:]' '[:lower:]')
          WORKFLOW_FILE=".github/workflows/${WORKFLOW_FILE_NAME}.yml"
          
          # Check if workflow file exists
          if [ ! -f "$WORKFLOW_FILE" ]; then
            echo "Workflow file not found at $WORKFLOW_FILE"
            exit 0
          fi
          
          CONTENT=$(head -c 1000 "$WORKFLOW_FILE")
          
          cat > /tmp/optimization_prompt.json <<'EOF'
          {
            "model": "gpt-3.5-turbo",
            "messages": [
              {
                "role": "system",
                "content": "Suggest 2-3 specific optimizations to improve workflow performance and reliability."
              },
              {
                "role": "user",
                "content": "Suggest optimizations for this workflow configuration"
              }
            ],
            "max_tokens": 200,
            "temperature": 0.7
          }
          EOF
          
          RESPONSE=$(timeout 10 curl -s -X POST https://api.openai.com/v1/chat/completions \
            -H "Authorization: Bearer $OPENAI_API_KEY" \
            -H "Content-Type: application/json" \
            -d @/tmp/optimization_prompt.json 2>/dev/null || echo '{"choices":[{"message":{"content":"Optimizations unavailable"}}]}')
          
          SUGGESTIONS=$(echo "$RESPONSE" | jq -r '.choices[0].message.content // "No suggestions"' 2>/dev/null || echo "API error")
          echo "suggestions<<EOF" >> $GITHUB_OUTPUT
          echo "$SUGGESTIONS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
        continue-on-error: false

      - name: Log analysis summary
        run: |
          echo "## Failure Analysis Results"
          echo ""
          echo "**Workflow:** ${{ steps.workflow.outputs.workflow_name }}"
          echo "**Run ID:** ${{ steps.workflow.outputs.run_id }}"
          echo ""
          echo "### AI Analysis"
          echo "${{ steps.ai_analysis.outputs.analysis || steps.fallback_analysis.outputs.analysis }}"
          echo ""
          if [ -n "${{ steps.optimization.outputs.suggestions }}" ]; then
            echo "### Optimization Suggestions"
            echo "${{ steps.optimization.outputs.suggestions }}"
          fi

  detect-anomalies:
    name: Detect performance anomalies
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion == 'success'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Fetch historical workflow data
        id: history
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Get last 10 successful runs  
          gh run list \
            --json "databaseId,name,updatedAt,status" \
            --limit 10 > /tmp/runs.json 2>/dev/null || echo "[]" > /tmp/runs.json
        continue-on-error: false

      - name: Analyze performance trends (if data available)
        if: env.OPENAI_API_KEY != '' && env.OPENAI_API_KEY != 'null'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          echo "Performance analysis skipped (optional feature)"
        continue-on-error: false

---

## Configuration

### Prerequisites
1. Set up OpenAI API key (optional, falls back to basic analysis)
   ```bash
   gh secret set OPENAI_API_KEY
   ```

2. Enable issue creation (workflow already has permissions)

### Features

âœ… **Automated Failure Analysis**
- AI-powered root cause identification
- Specific remediation suggestions
- Automatic issue creation

âœ… **Optimization Suggestions**
- Performance improvement recommendations
- Best practices identification
- Workflow-specific suggestions

âœ… **Anomaly Detection**
- Performance regression detection
- Trend analysis
- Historical comparison

### Cost Considerations

- Each analysis uses ~500 tokens (GPT-3.5)
- Typical cost: $0.001-0.005 per failure
- Consider adding cost controls in OpenAI account

### Fallback Behavior

If OpenAI API is unavailable:
- Basic failure analysis still runs
- Generic troubleshooting suggestions provided
- Issues still created with logs
- No token usage or costs

---

## Monitoring

**Issues Created:** Check GitHub Issues with label `ai-analysis`

**Status:** Review workflow runs in Actions tab

**Logs:** View full AI responses in workflow logs
