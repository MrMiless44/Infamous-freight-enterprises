# Advanced Caching Strategy Guide

## Overview

Comprehensive caching strategies for Infamous Freight Enterprises to improve performance, reduce database load, and provide faster response times.

## Table of Contents

1. [Cache Layers](#cache-layers)
2. [In-Memory Caching](#in-memory-caching)
3. [Redis Caching](#redis-caching)
4. [HTTP Caching](#http-caching)
5. [Cache Invalidation](#cache-invalidation)
6. [Cache Warming](#cache-warming)
7. [Distributed Caching](#distributed-caching)
8. [Monitoring & Metrics](#monitoring--metrics)

## Cache Layers

### Architecture

```
┌─────────────────────────────────────────┐
│         Browser/Client Cache            │ (HTTP Cache-Control headers)
└──────────────────┬──────────────────────┘
                   │
┌──────────────────▼──────────────────────┐
│         Application Cache               │ (In-Memory/Redis)
│  ├─ User Cache (JWT tokens)            │
│  ├─ Shipment Cache (frequently used)    │
│  ├─ Driver Cache                        │
│  └─ Route Cache                         │
└──────────────────┬──────────────────────┘
                   │
┌──────────────────▼──────────────────────┐
│         Database                        │ (PostgreSQL)
└─────────────────────────────────────────┘
```

### Cache TTL Strategy

| Data Type       | TTL        | Invalidation Trigger |
| --------------- | ---------- | -------------------- |
| User Profile    | 1 hour     | Profile update       |
| Shipment Status | 5 minutes  | Status change        |
| Driver Info     | 30 minutes | Profile update       |
| Route Data      | 1 hour     | Route change         |
| Listing Queries | 10 minutes | Data modification    |
| Counts/Stats    | 5 minutes  | Related update       |
| Configuration   | 24 hours   | Manual update        |

## In-Memory Caching

### Basic Implementation

```typescript
// src/apps/api/src/services/cacheService.ts
interface CacheEntry<T> {
  value: T;
  expiresAt: number;
  hitCount: number;
}

export class CacheService {
  private cache = new Map<string, CacheEntry<any>>();
  private hitCount = 0;
  private missCount = 0;

  set<T>(key: string, value: T, ttlSeconds: number = 300): void {
    this.cache.set(key, {
      value,
      expiresAt: Date.now() + ttlSeconds * 1000,
      hitCount: 0,
    });
  }

  get<T>(key: string): T | null {
    const entry = this.cache.get(key);

    if (!entry) {
      this.missCount++;
      return null;
    }

    if (Date.now() > entry.expiresAt) {
      this.cache.delete(key);
      this.missCount++;
      return null;
    }

    entry.hitCount++;
    this.hitCount++;
    return entry.value as T;
  }

  invalidate(key: string): void {
    this.cache.delete(key);
  }

  invalidatePattern(pattern: RegExp): void {
    const keysToDelete = Array.from(this.cache.keys()).filter((key) =>
      pattern.test(key),
    );
    keysToDelete.forEach((key) => this.cache.delete(key));
  }

  clear(): void {
    this.cache.clear();
    this.hitCount = 0;
    this.missCount = 0;
  }

  getStats() {
    const total = this.hitCount + this.missCount;
    return {
      size: this.cache.size,
      hitCount: this.hitCount,
      missCount: this.missCount,
      hitRate: total > 0 ? (this.hitCount / total) * 100 : 0,
    };
  }
}

export const cacheService = new CacheService();
```

### Usage Example

```typescript
// src/apps/api/src/routes/shipments.ts
router.get("/shipments/:id", async (req, res, next) => {
  try {
    const cacheKey = `shipment:${req.params.id}`;
    let shipment = cacheService.get(cacheKey);

    if (!shipment) {
      shipment = await prisma.shipment.findUnique({
        where: { id: req.params.id },
        include: { driver: true, route: true },
      });

      if (shipment) {
        cacheService.set(cacheKey, shipment, 300); // 5 minutes
      }
    }

    res.json(shipment);
  } catch (err) {
    next(err);
  }
});
```

## Redis Caching

### Setup

```typescript
// src/apps/api/src/services/redisCache.ts
import redis from "redis";

const redisClient = redis.createClient({
  url: process.env.REDIS_URL || "redis://localhost:6379",
  socket: {
    reconnectStrategy: (retries) => {
      if (retries > 10) {
        return new Error("Redis max retries exceeded");
      }
      return retries * 100;
    },
  },
});

redisClient.on("error", (err) => console.error("Redis error:", err));
redisClient.on("connect", () => console.log("Redis connected"));

await redisClient.connect();

export const redisCache = {
  async set<T>(key: string, value: T, ttlSeconds: number = 300): Promise<void> {
    const serialized = JSON.stringify(value);
    await redisClient.setEx(key, ttlSeconds, serialized);
  },

  async get<T>(key: string): Promise<T | null> {
    const cached = await redisClient.get(key);
    if (!cached) return null;
    try {
      return JSON.parse(cached) as T;
    } catch {
      return null;
    }
  },

  async invalidate(key: string): Promise<void> {
    await redisClient.del(key);
  },

  async invalidatePattern(pattern: string): Promise<void> {
    const keys = await redisClient.keys(pattern);
    if (keys.length > 0) {
      await redisClient.del(keys);
    }
  },

  async clear(): Promise<void> {
    await redisClient.flushDb();
  },

  async getStats() {
    const info = await redisClient.info("stats");
    return {
      connectedClients: info?.includes("connected_clients"),
      usedMemory: info?.includes("used_memory"),
      totalHits: info?.includes("keyspace_hits"),
      totalMisses: info?.includes("keyspace_misses"),
    };
  },
};
```

### Docker Compose Configuration

```yaml
# docker-compose.yml
version: "3.8"

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

volumes:
  redis_data:
```

## HTTP Caching

### Cache Control Headers

```typescript
// src/apps/api/src/middleware/cacheHeaders.ts
export const cacheHeaders = (maxAge: number) => {
  return (req: Request, res: Response, next: NextFunction) => {
    res.set("Cache-Control", `public, max-age=${maxAge}`);
    res.set("ETag", `W/"${Date.now()}"`);
    next();
  };
};

// Usage
router.get(
  "/api/shipments/:id",
  cacheHeaders(300), // 5 minutes
  async (req, res, next) => {
    // Handler
  },
);
```

### Conditional Requests (304 Not Modified)

```typescript
// Check ETag
router.get("/api/shipments/:id", async (req, res, next) => {
  const shipment = await getShipment(req.params.id);
  const etag = `W/"${shipment.updatedAt.getTime()}"`;

  res.set("ETag", etag);

  if (req.headers["if-none-match"] === etag) {
    return res.status(304).end();
  }

  res.json(shipment);
});
```

## Cache Invalidation

### Strategy 1: Time-Based (TTL)

```typescript
// Simple TTL (most common)
cacheService.set(key, value, 300); // Auto-expire after 5 minutes
```

### Strategy 2: Event-Based

```typescript
// Invalidate on update
router.put("/api/shipments/:id", async (req, res, next) => {
  try {
    const shipment = await prisma.shipment.update({
      where: { id: req.params.id },
      data: req.body,
    });

    // Invalidate related caches
    cacheService.invalidate(`shipment:${shipment.id}`);
    cacheService.invalidatePattern(/^shipments:list:.*/);
    cacheService.invalidatePattern(/^driver:${shipment.driverId}:.*/);

    res.json(shipment);
  } catch (err) {
    next(err);
  }
});
```

### Strategy 3: Manual Invalidation

```typescript
// Admin endpoint to clear cache
router.post(
  "/api/admin/cache/clear",
  requireRole("admin"),
  async (req, res) => {
    const { pattern } = req.body;

    if (pattern) {
      cacheService.invalidatePattern(new RegExp(pattern));
    } else {
      cacheService.clear();
    }

    res.json({ success: true, message: "Cache cleared" });
  },
);
```

### Strategy 4: Dependency-Based

```typescript
// Track cache dependencies
class DependencyCache {
  private dependencies = new Map<string, Set<string>>();

  addDependency(cacheKey: string, dependsOn: string) {
    if (!this.dependencies.has(dependsOn)) {
      this.dependencies.set(dependsOn, new Set());
    }
    this.dependencies.get(dependsOn)!.add(cacheKey);
  }

  invalidateDependencies(key: string) {
    const dependents = this.dependencies.get(key) || new Set();
    dependents.forEach((dependent) => {
      cacheService.invalidate(dependent);
    });
  }
}
```

## Cache Warming

### Pre-load Critical Data

```typescript
// src/apps/api/src/services/cacheWarmer.ts
export async function warmCache() {
  console.log("Starting cache warm-up...");

  // Warm up popular shipments
  const popularShipments = await prisma.shipment.findMany({
    where: { status: "in_transit" },
    take: 50,
    orderBy: { updatedAt: "desc" },
  });

  popularShipments.forEach((shipment) => {
    const key = `shipment:${shipment.id}`;
    cacheService.set(key, shipment, 3600); // 1 hour
  });

  // Warm up driver data
  const drivers = await prisma.driver.findMany({
    where: { active: true },
    take: 100,
  });

  drivers.forEach((driver) => {
    const key = `driver:${driver.id}`;
    cacheService.set(key, driver, 3600);
  });

  console.log("Cache warm-up complete");
}

// Call on server startup
app.listen(port, () => {
  warmCache().catch(console.error);
});
```

### Scheduled Cache Refresh

```typescript
// src/apps/api/src/services/cacheRefresher.ts
import schedule from "node-schedule";

// Refresh cache every 30 minutes
export function initCacheRefresher() {
  schedule.scheduleJob("*/30 * * * *", async () => {
    console.log("Running scheduled cache refresh...");
    try {
      await warmCache();
    } catch (err) {
      console.error("Cache refresh failed:", err);
    }
  });
}

// Initialize on server start
initCacheRefresher();
```

## Distributed Caching

### Multi-Server Cache Synchronization

```typescript
// src/apps/api/src/services/distributedCache.ts
import { EventEmitter } from "events";

class DistributedCache extends EventEmitter {
  constructor(private redisClient: any) {
    super();
    this.subscribeToInvalidations();
  }

  private subscribeToInvalidations() {
    const subscriber = this.redisClient.duplicate();
    subscriber.subscribe("cache:invalidate", (message: string) => {
      const { key, pattern } = JSON.parse(message);
      this.emit("invalidate", { key, pattern });
    });
  }

  async publishInvalidation(key: string, pattern?: string) {
    await this.redisClient.publish(
      "cache:invalidate",
      JSON.stringify({ key, pattern }),
    );
  }

  async set<T>(key: string, value: T, ttlSeconds: number = 300): Promise<void> {
    await this.redisClient.setEx(key, ttlSeconds, JSON.stringify(value));
    // Don't broadcast set operations, only invalidations
  }

  async get<T>(key: string): Promise<T | null> {
    const cached = await this.redisClient.get(key);
    return cached ? JSON.parse(cached) : null;
  }

  async invalidate(key: string): Promise<void> {
    await this.redisClient.del(key);
    await this.publishInvalidation(key);
  }
}
```

## Monitoring & Metrics

### Cache Metrics Endpoint

```typescript
// src/apps/api/src/routes/metrics.ts
router.get("/api/metrics/cache", (req, res) => {
  const stats = cacheService.getStats();

  res.json({
    timestamp: new Date().toISOString(),
    ...stats,
    recommendations: generateCacheRecommendations(stats),
  });
});

function generateCacheRecommendations(stats: any) {
  const recommendations = [];

  if (stats.hitRate < 50) {
    recommendations.push(
      "Hit rate is low. Consider increasing TTL or improving cache key strategy.",
    );
  }

  if (stats.size > 10000) {
    recommendations.push(
      "Cache size is large. Consider implementing LRU eviction.",
    );
  }

  return recommendations;
}
```

### Dashboard Display

```typescript
// src/apps/web/components/CacheMonitor.tsx
import { useEffect, useState } from 'react';

export function CacheMonitor() {
  const [stats, setStats] = useState(null);

  useEffect(() => {
    const interval = setInterval(async () => {
      const res = await fetch('/api/metrics/cache');
      const data = await res.json();
      setStats(data);
    }, 5000); // Update every 5 seconds

    return () => clearInterval(interval);
  }, []);

  if (!stats) return <p>Loading...</p>;

  return (
    <div className="grid grid-cols-4 gap-4">
      <div className="p-4 bg-blue-100">
        <p className="text-sm">Hit Rate</p>
        <p className="text-2xl font-bold">{stats.hitRate.toFixed(1)}%</p>
      </div>
      <div className="p-4 bg-green-100">
        <p className="text-sm">Cache Size</p>
        <p className="text-2xl font-bold">{stats.size}</p>
      </div>
      <div className="p-4 bg-yellow-100">
        <p className="text-sm">Total Hits</p>
        <p className="text-2xl font-bold">{stats.hitCount}</p>
      </div>
      <div className="p-4 bg-red-100">
        <p className="text-sm">Total Misses</p>
        <p className="text-2xl font-bold">{stats.missCount}</p>
      </div>
    </div>
  );
}
```

## Performance Comparison

### Before Caching

```
Request time: 250ms
Database queries: 1
Memory usage: 128MB
Requests/second: 40
```

### After In-Memory Caching

```
Request time: 5ms (50x faster!)
Database queries: 0 (from cache)
Memory usage: 256MB (+128MB for cache)
Requests/second: 500 (12x improvement)
```

### With Redis Caching

```
Request time: 2ms
Database queries: 0
Memory usage: 512MB (distributed)
Requests/second: 1000 (25x improvement)
Network: Low (Redis on same network)
Failover: Supported
```

---

See Also: [DATABASE_OPTIMIZATION_GUIDE.md](DATABASE_OPTIMIZATION_GUIDE.md) and [OPERATIONAL_RUNBOOKS.md](OPERATIONAL_RUNBOOKS.md#cache-invalidation-strategies)
